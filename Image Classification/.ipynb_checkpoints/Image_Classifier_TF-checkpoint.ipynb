{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y-RDdZ46w21D"
   },
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "cpus"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9R6sUlPxyBgR",
    "outputId": "947006e2-88e6-46be-9d64-35a09a1f81c2"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for cpu in cpus:\n",
    "    tf.config.experimental.set_memory_growth(cpu, True)"
   ],
   "metadata": {
    "id": "uOfvcnt7x0dR"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "kkBK7CF9zz2i"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = '/content/drive/MyDrive/Colab Notebooks/dataset'"
   ],
   "metadata": {
    "id": "apVdp0A733hY"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.listdir(os.path.join(data_dir, 'normal'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9zbErkPd5c5k",
    "outputId": "38c95797-57cf-479c-ec01-8678042a1f87"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ],
   "metadata": {
    "id": "yZlJf9iK38ZD"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "image_exts"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86sb3rmx4HMa",
    "outputId": "9eed03cd-22a4-4f9e-e5b3-6fc4a0e4ebab"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ],
   "metadata": {
    "id": "A8pf5pbJ4JQR"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Load Data**"
   ],
   "metadata": {
    "id": "1WwbxO8vG1Pp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tf.data.Dataset"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "lD5HtKm2HCaf",
    "outputId": "434e6afa-0ed3-4e29-b1de-0c1290e0f3bc",
    "collapsed": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.keras.utils.image_dataset_from_directory??"
   ],
   "metadata": {
    "id": "v3jIL4INQ8Pj"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 1. Define 'data' ---\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',  # Infers labels from directory structure\n",
    "    label_mode='categorical',  # One-hot encoded labels\n",
    "    image_size=(256, 256),  # Adjust if your images have different dimensions\n",
    "    batch_size=8,  # Adjust based on your memory constraints\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFw2nz9xDD-5",
    "outputId": "cf3be0dc-54da-4a2b-921e-ba85fc1e7733"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ],
   "metadata": {
    "id": "97f90XPjDHfi"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch = data_iterator.next()"
   ],
   "metadata": {
    "id": "eBCBocPbRPfa"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch[0].shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WqaQFHTYz6v",
    "outputId": "f8651bb6-2e29-40a0-950d-b7b70e848ae2"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class_names = {\n",
    "    0: \"Circular\",\n",
    "    1: \"Normal\",\n",
    "    2: \"Overlapping\"\n",
    "}\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 25))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    # Convert NumPy array to a hashable type (e.g., integer)\n",
    "    label_index = np.argmax(batch[1][idx])  # Get index of the highest probability class\n",
    "    ax[idx].title.set_text(class_names.get(label_index, \"Unknown\"))\n",
    "\n",
    "    # Add x and y ticks (adjust values based on your image dimensions)\n",
    "    ax[idx].set_xticks(np.arange(0, img.shape[1], 50))  # Ticks every 50 pixels on x-axis\n",
    "    ax[idx].set_yticks(np.arange(0, img.shape[0], 50))  # Ticks every 50 pixels on y-axis\n",
    "\n",
    "    # Optionally, label the ticks with pixel values\n",
    "    ax[idx].set_xticklabels(np.arange(0, img.shape[1], 50))\n",
    "    ax[idx].set_yticklabels(np.arange(0, img.shape[0], 50))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "CLEcKw9eRhfY",
    "outputId": "24925782-8dec-4d5e-d504-325900969a13"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Scale Data**"
   ],
   "metadata": {
    "id": "0pFZTbgq31t7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "# important since it helps to perform transformation to convert image min to 0 and max to 1\n",
    "# important while working with data pipeline"
   ],
   "metadata": {
    "id": "qm_Urb2q3VVc"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data.as_numpy_iterator().next()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "KZUYQqM_37pE",
    "outputId": "c5b16248-3ad3-4595-aae3-a8ea39945d0f"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Split Data**"
   ],
   "metadata": {
    "id": "tltHKl2R4L1_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "len(data) # num of batches"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wq18i6N3kUgm",
    "outputId": "dfe31191-8add-4297-819f-f030add3891a"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#batch_size = 32"
   ],
   "metadata": {
    "id": "cxe938Jko9Ei"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train_batches = int(len(data) * 0.7) // batch_size\n",
    "# val_batches = int(len(data) * 0.2) // batch_size\n",
    "# test_batches = int(len(data) * 0.1) // batch_size"
   ],
   "metadata": {
    "id": "nAJC7Fryo__m"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test_batches"
   ],
   "metadata": {
    "id": "Dek9wS5xpZNv"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)+1"
   ],
   "metadata": {
    "id": "s4RnYv7v3-qb"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8XnZdLk4R84",
    "outputId": "1f21184e-ef7f-4f6f-bc1a-bdf3b2987649"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "# Established train, test and val partition"
   ],
   "metadata": {
    "id": "xWHZ-HT04U4w"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_labels = np.concatenate([y for x, y in train], axis=0)\n",
    "val_labels = np.concatenate([y for x, y in val], axis=0)\n",
    "test_labels = np.concatenate([y for x, y in test], axis=0)\n",
    "\n",
    "# One-hot encode the labels (if needed for your model)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ],
   "metadata": {
    "id": "VWGFMOAydfa8"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Building the Deep Learning Model**"
   ],
   "metadata": {
    "id": "5Cd7ZRde4d-B"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ],
   "metadata": {
    "id": "-MZ4MdX44kZH"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes = 3\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ],
   "metadata": {
    "id": "ZbUZz_CL8uaT"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "xUlGQ5Yd8vdm"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1FNvnw18yoM",
    "outputId": "17538b55-3b53-47c1-83c5-fb463dbcc9a0"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train**"
   ],
   "metadata": {
    "id": "zAc7IIeZFrBb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "logdir = 'logs'"
   ],
   "metadata": {
    "id": "ILdlYRmnFyHG"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ],
   "metadata": {
    "id": "td4tBCr5F3Ef"
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.tracebacklimit = 500"
   ],
   "metadata": {
    "id": "s2JCgzVFftYv"
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZTCqrosGMfh",
    "outputId": "c587d784-d804-48a5-df1e-ad57b26f4c62"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hist.history"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BkQnUYEXHGcx",
    "outputId": "cb2bb119-cdb4-4fff-eb6b-5fb77029da11"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plot Performance**"
   ],
   "metadata": {
    "id": "S5LQFdKZHmBQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "36h9ddD-Hvx9",
    "outputId": "ee66a3cc-eccc-4c4a-b4ee-0bb3d74e55b4"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "kTlnl7MHH_nT",
    "outputId": "d44796b8-5667-4615-b121-42539d3369a5"
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Evaluate Performance**"
   ],
   "metadata": {
    "id": "ESU3YKzmIUk4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ],
   "metadata": {
    "id": "QoQDcypiIYrx"
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Establishing instances\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ],
   "metadata": {
    "id": "35x1ozmkIdyv"
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxuwTm-nIfUT",
    "outputId": "c9ebfa75-25c1-4337-ff9e-f64b80d9c379"
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Precision:{pre.result()}, Recall:{re.result().numpy()}, Acuraccy:{acc.result().numpy}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQ5xhABWI75X",
    "outputId": "b6208eb1-48d4-450d-e9ef-d47377d4fd58"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Test**"
   ],
   "metadata": {
    "id": "ym0qLHinOTVU"
   }
  },
  {
   "cell_type": "code",
   "source": "# import cv2",
   "metadata": {
    "id": "sPl4ImweOVTX"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# img = cv2.imread('154006829.jpg')\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ],
   "metadata": {
    "id": "EGauMBeEPHGn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# resize = tf.image.resize(img, (256,256))\n",
    "# plt.imshow(resize.numpy().astype(int))\n",
    "# plt.show()"
   ],
   "metadata": {
    "id": "i5uQyCvBPI01"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# yhat = model.predict(np.expand_dims(resize/255, 0))",
   "metadata": {
    "id": "FjZIXeAxPK1q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# yhat",
   "metadata": {
    "id": "rEiNsFRIPNAC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# if yhat > 0.5:\n",
    "#     print(f'Predicted class is Sad')\n",
    "# else:\n",
    "#     print(f'Predicted class is Happy')"
   ],
   "metadata": {
    "id": "eeDN2KKyPPMm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and preprocess the image\n",
    "img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/eval1.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()\n",
    "\n",
    "# Predict the class\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "\n",
    "# Assuming you have 3 classes (Sad, Happy, Neutral)\n",
    "class_names = ['Circular', 'Normal', 'Overlapping']\n",
    "predicted_class = np.argmax(yhat)\n",
    "\n",
    "print(f'Image belong to the {class_names[predicted_class]} class')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "LV0rg4p3mGRO",
    "outputId": "eae7a1ef-5557-48cb-ce12-d254b75d602c"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Saving the model**"
   ],
   "metadata": {
    "id": "CFUpmSERNpv6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model"
   ],
   "metadata": {
    "id": "QRC_Bvb1NoYw"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save(os.path.join('models','imageclassifier.keras'))"
   ],
   "metadata": {
    "id": "-Iq-4vIUN1B_"
   },
   "execution_count": 48,
   "outputs": []
  }
 ]
}
