{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:16.774284Z",
     "start_time": "2024-06-12T06:19:16.738222Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ],
   "execution_count": 329,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:17.164773Z",
     "start_time": "2024-06-12T06:19:17.145748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "cpus"
   ],
   "id": "1f08eadb2ffe8583",
   "execution_count": 330,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:17.563954Z",
     "start_time": "2024-06-12T06:19:17.552201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for cpu in cpus:\n",
    "    tf.config.experimental.set_memory_growth(cpu, True)"
   ],
   "id": "d84794e73cc8507",
   "execution_count": 331,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:17.899608Z",
     "start_time": "2024-06-12T06:19:17.891859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "92bb07d410e9c49a",
   "execution_count": 332,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:18.294117Z",
     "start_time": "2024-06-12T06:19:18.284856Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir = 'dataset'",
   "id": "9c139bda03ceb841",
   "execution_count": 333,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:18.911130Z",
     "start_time": "2024-06-12T06:19:18.895571Z"
    }
   },
   "cell_type": "code",
   "source": "os.listdir(os.path.join(data_dir, 'intersecting'))",
   "id": "82e3f381b426ab0f",
   "execution_count": 334,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:19.348161Z",
     "start_time": "2024-06-12T06:19:19.340973Z"
    }
   },
   "cell_type": "code",
   "source": "image_exts = ['jpeg','jpg', 'bmp', 'png']",
   "id": "b0d1058ce1652ea8",
   "execution_count": 335,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:19.795021Z",
     "start_time": "2024-06-12T06:19:19.779831Z"
    }
   },
   "cell_type": "code",
   "source": "image_exts",
   "id": "d9708eb4c5a60bdb",
   "execution_count": 336,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:20.344092Z",
     "start_time": "2024-06-12T06:19:20.151245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ],
   "id": "24bd1dded4a40ad8",
   "execution_count": 337,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data",
   "id": "9d4bbbba3cada0d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:21.340782Z",
     "start_time": "2024-06-12T06:19:21.280169Z"
    }
   },
   "cell_type": "code",
   "source": "tf.data.Dataset",
   "id": "2d4fe6c405ef9882",
   "execution_count": 338,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:24.365329Z",
     "start_time": "2024-06-12T06:19:22.601761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 1. Define 'data' ---\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',  # Infers labels from directory structure\n",
    "    label_mode='categorical',  # One-hot encoded labels\n",
    "    image_size=(256, 256),  # Adjust if your images have different dimensions\n",
    "    batch_size=8,  # Adjust based on your memory constraints\n",
    ")"
   ],
   "id": "fa17cec9a05d70db",
   "execution_count": 339,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:25.032092Z",
     "start_time": "2024-06-12T06:19:24.503133Z"
    }
   },
   "cell_type": "code",
   "source": "data_iterator = data.as_numpy_iterator()",
   "id": "f1424b468debe67f",
   "execution_count": 340,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:26.802115Z",
     "start_time": "2024-06-12T06:19:26.178740Z"
    }
   },
   "cell_type": "code",
   "source": "batch = data_iterator.next()",
   "id": "5036fb007f0b6128",
   "execution_count": 341,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:27.663751Z",
     "start_time": "2024-06-12T06:19:27.611341Z"
    }
   },
   "cell_type": "code",
   "source": "batch[0].shape",
   "id": "7acf65edf06af2b0",
   "execution_count": 342,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:30.381426Z",
     "start_time": "2024-06-12T06:19:29.577490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = {\n",
    "    0: \"Circular\",\n",
    "    1: \"Intersecting\",\n",
    "    2: \"Normal\",\n",
    "    3: \"Overlapping\",\n",
    "}\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 25))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    # Convert NumPy array to a hashable type (e.g., integer)\n",
    "    label_index = np.argmax(batch[1][idx])  # Get index of the highest probability class\n",
    "    ax[idx].title.set_text(class_names.get(label_index, \"Unknown\"))\n",
    "\n",
    "    # Add x and y ticks (adjust values based on your image dimensions)\n",
    "    ax[idx].set_xticks(np.arange(0, img.shape[1], 50))  # Ticks every 50 pixels on x-axis\n",
    "    ax[idx].set_yticks(np.arange(0, img.shape[0], 50))  # Ticks every 50 pixels on y-axis\n",
    "\n",
    "    # Optionally, label the ticks with pixel values\n",
    "    ax[idx].set_xticklabels(np.arange(0, img.shape[1], 50))\n",
    "    ax[idx].set_yticklabels(np.arange(0, img.shape[0], 50))\n",
    "\n",
    "plt.show()"
   ],
   "id": "b9d7df7c6837baa6",
   "execution_count": 343,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scale Data",
   "id": "f80931e505010041"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:34.630661Z",
     "start_time": "2024-06-12T06:19:34.601605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data.map(lambda x,y: (x/255, y))\n",
    "# important since it helps to perform transformation to convert image min to 0 and max to 1\n",
    "# important while working with data pipeline"
   ],
   "id": "cf95921d3a7a2d41",
   "execution_count": 344,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:36.012779Z",
     "start_time": "2024-06-12T06:19:35.929744Z"
    }
   },
   "cell_type": "code",
   "source": "data.as_numpy_iterator().next()",
   "id": "3666dba7457da7e1",
   "execution_count": 345,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split Data",
   "id": "f737a5541d0c10a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:37.400366Z",
     "start_time": "2024-06-12T06:19:37.391055Z"
    }
   },
   "cell_type": "code",
   "source": "len(data) # num of batches",
   "id": "7721b9913f7cff37",
   "execution_count": 346,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:38.237331Z",
     "start_time": "2024-06-12T06:19:38.189809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(len(data)*.7)-1\n",
    "val_size = int(len(data)*.2)+2\n",
    "test_size = int(len(data)*.1)+1"
   ],
   "id": "bac979a8e2861b07",
   "execution_count": 347,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:39.903798Z",
     "start_time": "2024-06-12T06:19:39.854453Z"
    }
   },
   "cell_type": "code",
   "source": "train_size",
   "id": "2ee0f1086ecb09af",
   "execution_count": 348,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:42.933819Z",
     "start_time": "2024-06-12T06:19:42.701387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "# Established train, test and val partition"
   ],
   "id": "538a86bc24613503",
   "execution_count": 349,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:46.013265Z",
     "start_time": "2024-06-12T06:19:45.175068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_labels = np.concatenate([y for x, y in train], axis=0)\n",
    "val_labels = np.concatenate([y for x, y in val], axis=0)\n",
    "test_labels = np.concatenate([y for x, y in test], axis=0)\n",
    "\n",
    "# One-hot encode the labels (if needed for your model)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ],
   "id": "3c0f8b2dd9491a35",
   "execution_count": 350,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Building the model",
   "id": "139d9905058e46a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:47.635006Z",
     "start_time": "2024-06-12T06:19:47.629032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ],
   "id": "1f0c9a41bbf3b772",
   "execution_count": 351,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:48.433335Z",
     "start_time": "2024-06-12T06:19:48.313021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = 4\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
   ],
   "id": "7a009b60149ea845",
   "execution_count": 352,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:49.735044Z",
     "start_time": "2024-06-12T06:19:49.723416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "edfdf4143d09ce7b",
   "execution_count": 353,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:51.903476Z",
     "start_time": "2024-06-12T06:19:51.846072Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "abd5fa2a2feccfc8",
   "execution_count": 354,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:53.339518Z",
     "start_time": "2024-06-12T06:19:53.335044Z"
    }
   },
   "cell_type": "code",
   "source": "logdir = 'logs'",
   "id": "852f20a55c8c4831",
   "execution_count": 355,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:19:54.752854Z",
     "start_time": "2024-06-12T06:19:54.739981Z"
    }
   },
   "cell_type": "code",
   "source": "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)",
   "id": "7afaba3461ab9f26",
   "execution_count": 356,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:16.018577Z",
     "start_time": "2024-06-12T06:19:55.750643Z"
    }
   },
   "cell_type": "code",
   "source": "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])",
   "id": "b9a43dbca7eceeb2",
   "execution_count": 357,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:20.203887Z",
     "start_time": "2024-06-12T06:20:20.192837Z"
    }
   },
   "cell_type": "code",
   "source": "hist.history",
   "id": "6cde01bd7b338a17",
   "execution_count": 358,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:28.164293Z",
     "start_time": "2024-06-12T06:20:26.049077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "id": "eee165a7b6a8729c",
   "execution_count": 359,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:33.522955Z",
     "start_time": "2024-06-12T06:20:33.354124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "id": "46f7957a82bb623d",
   "execution_count": 360,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "776cc5bab596c4ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:36.437438Z",
     "start_time": "2024-06-12T06:20:36.430879Z"
    }
   },
   "cell_type": "code",
   "source": "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy",
   "id": "d017c13a5c899f7d",
   "execution_count": 361,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:37.494867Z",
     "start_time": "2024-06-12T06:20:37.471576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Establishing instances\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ],
   "id": "ff991a3eb179c570",
   "execution_count": 362,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:38.963426Z",
     "start_time": "2024-06-12T06:20:38.501827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ],
   "id": "a71887bd5590185e",
   "execution_count": 363,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:39.461857Z",
     "start_time": "2024-06-12T06:20:39.445053Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Precision:{pre.result()}, Recall:{re.result().numpy()}, Acuraccy:{acc.result().numpy}')",
   "id": "e2fbc90c3bc151c8",
   "execution_count": 364,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing",
   "id": "bb819c354242bdba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:20:43.500093Z",
     "start_time": "2024-06-12T06:20:43.461802Z"
    }
   },
   "cell_type": "code",
   "source": "import cv2",
   "id": "76f8eb355cf42a30",
   "execution_count": 365,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:23:00.668047Z",
     "start_time": "2024-06-12T06:23:00.001368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and preprocess the image\n",
    "img = cv2.imread('intersecting.jpeg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()\n",
    "\n",
    "# Predict the class\n",
    "predict = model.predict(np.expand_dims(resize/255, 0))\n",
    "\n",
    "class_names = ['Circular', 'Intersecting', 'Normal', 'Overlapping']\n",
    "predicted_class = np.argmax(predict)\n",
    "\n",
    "print(f'Image belong to the {class_names[predicted_class]} class')"
   ],
   "id": "af2eb9b88aa485aa",
   "execution_count": 368,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving the model",
   "id": "2cd9efa0f5af772d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:23:16.435993Z",
     "start_time": "2024-06-12T06:23:16.430816Z"
    }
   },
   "cell_type": "code",
   "source": "from tensorflow.keras.models import load_model",
   "id": "5888971318ad4f9f",
   "execution_count": 372,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:10:50.184421Z",
     "start_time": "2024-06-11T08:10:49.773452Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('imageclassifier_4.keras')",
   "id": "78474d6688359318",
   "execution_count": 323,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:23:35.082168Z",
     "start_time": "2024-06-12T06:23:33.645015Z"
    }
   },
   "cell_type": "code",
   "source": "prediction = tf.keras.models.load_model('imageclassifier_4.keras')",
   "id": "303ac6d46695e101",
   "execution_count": 373,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:23:35.843888Z",
     "start_time": "2024-06-12T06:23:35.836472Z"
    }
   },
   "cell_type": "code",
   "source": "prediction",
   "id": "f0c807fe8b5a9c07",
   "execution_count": 374,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:23:37.689237Z",
     "start_time": "2024-06-12T06:23:37.236481Z"
    }
   },
   "cell_type": "code",
   "source": "yhatnew = prediction.predict(np.expand_dims(resize/255, 0))",
   "id": "271cffe1755d66c1",
   "execution_count": 375,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T06:23:38.446571Z",
     "start_time": "2024-06-12T06:23:38.441024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = ['Circular', 'Intersecting', 'Normal', 'Overlapping']\n",
    "predicted_class = np.argmax(predict)\n",
    "\n",
    "print(f'Image belong to the {class_names[predicted_class]} class')"
   ],
   "id": "a4ddeaa96fc36ca8",
   "execution_count": 376,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "6ebee00928a9e444",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
