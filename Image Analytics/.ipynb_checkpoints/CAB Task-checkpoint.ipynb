{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4768e6-896d-4188-b4c0-c9e23cbbc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"2.png\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray', gray)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Display the original image and the edge image\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Edge Image\", edges)\n",
    "\n",
    "# Wait for a key press and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608d03a3-83b5-47ec-a7e9-3bc8b8e3aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def inpaint_text(img_path, remove_list, pipeline):\n",
    "    # read image\n",
    "    img = cv2.imread(img_path)\n",
    "    # Prediction_groups is a list of (word, box) tuples\n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    #print image with annotation and boxes\n",
    "    keras_ocr.tools.drawAnnotations(image=img, predictions=prediction_groups[0])\n",
    "\n",
    "    for box in prediction_groups[0]:\n",
    "        if box[0] in remove_list:\n",
    "            x0, y0 = box[1][0]\n",
    "            x1, y1 = box[1][1]\n",
    "            x2, y2 = box[1][2]\n",
    "            x3, y3 = box[1][3]\n",
    "            x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "            x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "            thickness = int(math.sqrt((x2 - x1)**2 + (y2 - y1)**2))\n",
    "\n",
    "            # create mask\n",
    "            mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "            cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255, thickness)\n",
    "\n",
    "            # inpaint the image\n",
    "            img_inpainted = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "\n",
    "    return img_inpainted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741cb44d-bb6c-475a-b79e-9299544eb204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.feature\n",
    "\n",
    "def find_edges(img_path):\n",
    "    # load and display original image as grayscale\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # apply Canny edge detection\n",
    "    edges = skimage.feature.canny(\n",
    "        image=image,\n",
    "        sigma=2,\n",
    "        low_threshold=0.1,\n",
    "        high_threshold=0.5\n",
    "    )\n",
    "\n",
    "    # display edges\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    # count edges\n",
    "    edge_count = np.sum(edges)\n",
    "    print(f\"Number of edges: {edge_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b889684-aeae-4f8d-aad9-e8f5efa49e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\KIIT\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Downloading C:\\Users\\KIIT\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m remove_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# define pipeline\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m keras_ocr\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mPipeline()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# read image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     detector \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mDetector()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m recognition\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m detector\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:388\u001b[0m, in \u001b[0;36mRecognizer.__init__\u001b[1;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet \u001b[38;5;241m=\u001b[39m alphabet\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblank_label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(alphabet)\n\u001b[0;32m    383\u001b[0m (\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_model,\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_model,\n\u001b[1;32m--> 388\u001b[0m ) \u001b[38;5;241m=\u001b[39m build_model(alphabet\u001b[38;5;241m=\u001b[39malphabet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_params)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     weights_dict \u001b[38;5;241m=\u001b[39m PRETRAINED_WEIGHTS[weights]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:277\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[0;32m    275\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(locnet_y)\n\u001b[0;32m    276\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(locnet_y)\n\u001b[1;32m--> 277\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m    279\u001b[0m     weights\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    280\u001b[0m         np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m6\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m    282\u001b[0m     ],\n\u001b[0;32m    283\u001b[0m )(locnet_y)\n\u001b[0;32m    284\u001b[0m localization_net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mstn_input_layer, outputs\u001b[38;5;241m=\u001b[39mlocnet_y)\n\u001b[0;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(_transform, output_shape\u001b[38;5;241m=\u001b[39mstn_input_output_shape)(\n\u001b[0;32m    286\u001b[0m     [x, localization_net(x)]\n\u001b[0;32m    287\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     units,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "import keras_ocr\n",
    "\n",
    "remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# define pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# read image\n",
    "img = cv2.imread('2.png')\n",
    "\n",
    "# remove numbers from the image\n",
    "img_inpainted = inpaint_text('2.png', remove_list, pipeline)\n",
    "\n",
    "# save the image without numbers\n",
    "cv2.imwrite('2_no_numbers.png', img_inpainted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87ed95-f188-4b9e-a0a4-5a22c719fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find edges\n",
    "find_edges('2_no_numbers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cdb97e-7e6d-4d1a-9070-67e08075f347",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'draw_box_on_image' from 'keras_ocr.tools' (C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\tools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_ocr\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_ocr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_box_on_image\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Define the list of numbers to remove\u001b[39;00m\n\u001b[0;32m      7\u001b[0m remove_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'draw_box_on_image' from 'keras_ocr.tools' (C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\tools.py)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras_ocr\n",
    "import numpy as np\n",
    "from keras_ocr.tools import draw_box_on_image\n",
    "\n",
    "# Define the list of numbers to remove\n",
    "remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Define the image path\n",
    "image_path = 'image.png'\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Recognize text in the image\n",
    "prediction_groups = pipeline.recognize([image_path])[0]\n",
    "\n",
    "# Create a blank image with the same size as the input image\n",
    "height, width, _ = cv2.imread(image_path).shape\n",
    "blank_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Loop through the recognized text and apply a mask on the input image\n",
    "for group in prediction_groups:\n",
    "    for box, text in group:\n",
    "        if text in remove_list:\n",
    "            x, y, w, h = box\n",
    "            # Draw a red rectangle on the input image\n",
    "            draw_box_on_image(image_path, box, color=(0, 0, 255))\n",
    "            # Apply a mask on the blank image\n",
    "            blank_image[y:y+h, x:x+w] = 255\n",
    "\n",
    "# Inpaint the masked regions in the blank image\n",
    "inpainted_image = cv2.inpaint(blank_image, np.array(cv2.bitwise_not(blank_image), dtype=np.uint8), 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "# Save the inpainted image\n",
    "cv2.imwrite('inpainted_image.png', inpainted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65e0b7b-3eaa-4e8b-a215-da00ada3d4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\KIIT\\.keras-ocr\\craft_mlt_25k.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define the pipeline\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m keras_ocr\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mPipeline()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Recognize text in the image\u001b[39;00m\n\u001b[0;32m     16\u001b[0m prediction_groups \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrecognize([image_path])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     detector \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mDetector()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m recognition\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m detector\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:388\u001b[0m, in \u001b[0;36mRecognizer.__init__\u001b[1;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet \u001b[38;5;241m=\u001b[39m alphabet\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblank_label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(alphabet)\n\u001b[0;32m    383\u001b[0m (\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_model,\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_model,\n\u001b[1;32m--> 388\u001b[0m ) \u001b[38;5;241m=\u001b[39m build_model(alphabet\u001b[38;5;241m=\u001b[39malphabet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_params)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     weights_dict \u001b[38;5;241m=\u001b[39m PRETRAINED_WEIGHTS[weights]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:277\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[0;32m    275\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(locnet_y)\n\u001b[0;32m    276\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(locnet_y)\n\u001b[1;32m--> 277\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m    279\u001b[0m     weights\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    280\u001b[0m         np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m6\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m    282\u001b[0m     ],\n\u001b[0;32m    283\u001b[0m )(locnet_y)\n\u001b[0;32m    284\u001b[0m localization_net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mstn_input_layer, outputs\u001b[38;5;241m=\u001b[39mlocnet_y)\n\u001b[0;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(_transform, output_shape\u001b[38;5;241m=\u001b[39mstn_input_output_shape)(\n\u001b[0;32m    286\u001b[0m     [x, localization_net(x)]\n\u001b[0;32m    287\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     units,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras_ocr\n",
    "import numpy as np\n",
    "from keras_ocr.tools import read, drawAnnotations\n",
    "\n",
    "# Define the list of numbers to remove\n",
    "remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Define the image path\n",
    "image_path = '2.png'\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Recognize text in the image\n",
    "prediction_groups = pipeline.recognize([image_path])[0]\n",
    "\n",
    "# Create a blank image with the same size as the input image\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape\n",
    "blank_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Loop through the recognized text and apply a mask on the input image\n",
    "for group in prediction_groups:\n",
    "    for box, text in group:\n",
    "        if text in remove_list:\n",
    "            x, y, w, h = box\n",
    "            # Apply a mask on the blank image\n",
    "            blank_image[y:y+h, x:x+w] = image[y:y+h, x:x+w]\n",
    "\n",
    "# Inpaint the masked regions in the blank image\n",
    "inpainted_image = cv2.inpaint(blank_image, np.zeros(blank_image.shape, dtype=np.uint8), 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "# Save the inpainted image\n",
    "cv2.imwrite('2_no_numbers.png', inpainted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dfa268-960c-4003-9787-68577d209d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab07fe9-fada-4053-a184-d7a480a1ea98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\KIIT\\.keras-ocr\\craft_mlt_25k.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(inpainted_img)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# keras-ocr will automatically download pretrained\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# weights for the detector and recognizer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m keras_ocr\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mPipeline()\n\u001b[0;32m     59\u001b[0m img_text_removed \u001b[38;5;241m=\u001b[39m inpaint_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.png\u001b[39m\u001b[38;5;124m'\u001b[39m, pipeline)\n\u001b[0;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img_text_removed)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     detector \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mDetector()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m recognition\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m detector\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:388\u001b[0m, in \u001b[0;36mRecognizer.__init__\u001b[1;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet \u001b[38;5;241m=\u001b[39m alphabet\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblank_label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(alphabet)\n\u001b[0;32m    383\u001b[0m (\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_model,\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_model,\n\u001b[1;32m--> 388\u001b[0m ) \u001b[38;5;241m=\u001b[39m build_model(alphabet\u001b[38;5;241m=\u001b[39malphabet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_params)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     weights_dict \u001b[38;5;241m=\u001b[39m PRETRAINED_WEIGHTS[weights]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:277\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[0;32m    275\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(locnet_y)\n\u001b[0;32m    276\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(locnet_y)\n\u001b[1;32m--> 277\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m    279\u001b[0m     weights\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    280\u001b[0m         np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m6\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m    282\u001b[0m     ],\n\u001b[0;32m    283\u001b[0m )(locnet_y)\n\u001b[0;32m    284\u001b[0m localization_net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mstn_input_layer, outputs\u001b[38;5;241m=\u001b[39mlocnet_y)\n\u001b[0;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(_transform, output_shape\u001b[38;5;241m=\u001b[39mstn_input_output_shape)(\n\u001b[0;32m    286\u001b[0m     [x, localization_net(x)]\n\u001b[0;32m    287\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     units,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#General Approach.....\n",
    "#Use keras OCR to detect text, define a mask around the text, and inpaint the\n",
    "#masked regions to remove the text.\n",
    "#To apply the mask we need to provide the coordinates of the starting and \n",
    "#the ending points of the line, and the thickness of the line\n",
    "\n",
    "#The start point will be the mid-point between the top-left corner and \n",
    "#the bottom-left corner of the box. \n",
    "#the end point will be the mid-point between the top-right corner and the bottom-right corner.\n",
    "#The following function does exactly that.\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2)/2)\n",
    "    y_mid = int((y1 + y2)/2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "#Main function that detects text and inpaints. \n",
    "#Inputs are the image path and kreas_ocr pipeline\n",
    "def inpaint_text(img_path, pipeline):\n",
    "    # read the image \n",
    "    img = keras_ocr.tools.read(img_path) \n",
    "    \n",
    "    # Recogize text (and corresponding regions)\n",
    "    # Each list of predictions in prediction_groups is a list of\n",
    "    # (word, box) tuples. \n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    \n",
    "    #Define the mask for inpainting\n",
    "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    for box in prediction_groups[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1] \n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3] \n",
    "        \n",
    "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "        \n",
    "        #For the line thickness, we will calculate the length of the line between \n",
    "        #the top-left corner and the bottom-left corner.\n",
    "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
    "        \n",
    "        #Define the line and inpaint\n",
    "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,    \n",
    "        thickness)\n",
    "        inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "                 \n",
    "    return(inpainted_img)\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "img_text_removed = inpaint_text('2.png', pipeline)\n",
    "\n",
    "plt.imshow(img_text_removed)\n",
    "\n",
    "cv2.imwrite('2.png', cv2.cvtColor(img_text_removed, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6a2bcc-f6fd-4321-8cd2-8e90bad019e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('2.png', 0)\n",
    "\n",
    "# Thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 500:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, (0), 1)\n",
    "\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1d6607c-29da-474b-a269-0bcab349ad8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('processed_image.png', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "438b953f-f783-42a1-9c52-e66c9dd710d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73e0a11-0602-4e31-8984-45314a1be498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('3.png', 0)\n",
    "\n",
    "# Thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 20, 30, cv2.THRESH_BINARY_INV)\n",
    "# 4.png:46-49, 3.png :20, 2.png:25\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "# # Perform erosion and dilation to remove noise and fill gaps\n",
    "# kernel = np.ones((100,10), np.uint8)\n",
    "# thresh = cv2.erode(thresh, kernel, iterations=50)\n",
    "# thresh = cv2.dilate(thresh, kernel, iterations=50)\n",
    "\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 30:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, (0), 1)\n",
    "\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3bb9e53-6cbc-4972-9534-b1a9fbc31e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the image to create a binary mask\n",
    "_, binary_mask = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# #adaptive threshold\n",
    "# adaptive_thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 17, 7)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "# Draw the detected contours (lines) on the output image\n",
    "for contour in contours:\n",
    "    cv2.drawContours(output, [contour], -1, (0), 2)\n",
    "\n",
    "# Display the output image\n",
    "cv2.imshow('Extracted Lines', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82b90e52-8e7a-4327-8e1c-0bf160ce4089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\KIIT\\.keras-ocr\\craft_mlt_25k.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_ocr\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the Keras-OCR pipeline\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m keras_ocr\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mPipeline()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Read the image\u001b[39;00m\n\u001b[0;32m      8\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     detector \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mDetector()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m recognition\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m detector\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:388\u001b[0m, in \u001b[0;36mRecognizer.__init__\u001b[1;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet \u001b[38;5;241m=\u001b[39m alphabet\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblank_label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(alphabet)\n\u001b[0;32m    383\u001b[0m (\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_model,\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_model,\n\u001b[1;32m--> 388\u001b[0m ) \u001b[38;5;241m=\u001b[39m build_model(alphabet\u001b[38;5;241m=\u001b[39malphabet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_params)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     weights_dict \u001b[38;5;241m=\u001b[39m PRETRAINED_WEIGHTS[weights]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:277\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[0;32m    275\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(locnet_y)\n\u001b[0;32m    276\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(locnet_y)\n\u001b[1;32m--> 277\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m    279\u001b[0m     weights\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    280\u001b[0m         np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m6\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m    282\u001b[0m     ],\n\u001b[0;32m    283\u001b[0m )(locnet_y)\n\u001b[0;32m    284\u001b[0m localization_net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mstn_input_layer, outputs\u001b[38;5;241m=\u001b[39mlocnet_y)\n\u001b[0;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(_transform, output_shape\u001b[38;5;241m=\u001b[39mstn_input_output_shape)(\n\u001b[0;32m    286\u001b[0m     [x, localization_net(x)]\n\u001b[0;32m    287\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     units,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "\n",
    "# Load the Keras-OCR pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Read the image\n",
    "image_path = '2.png'\n",
    "image = keras_ocr.tools.read(image_path)\n",
    "\n",
    "# Perform OCR on the image\n",
    "result = pipeline.recognize([image])\n",
    "\n",
    "# Extract the recognized text\n",
    "recognized_text = result[0][0]\n",
    "\n",
    "# Display the recognized text\n",
    "print(\"Recognized Text:\")\n",
    "print(recognized_text)\n",
    "\n",
    "# Display the image with bounding boxes around detected text\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image)\n",
    "keras_ocr.tools.drawAnnotations(image=image, predictions=result, ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42746438-67f6-4d5c-9494-69fe6e4d6423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\KIIT\\.keras-ocr\\craft_mlt_25k.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(inpainted_img)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# keras-ocr will automatically download pretrained\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# weights for the detector and recognizer.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m keras_ocr\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mPipeline()\n\u001b[0;32m     59\u001b[0m img_text_removed \u001b[38;5;241m=\u001b[39m inpaint_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.png\u001b[39m\u001b[38;5;124m'\u001b[39m, pipeline)\n\u001b[0;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img_text_removed)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\pipeline.py:22\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, detector, recognizer, scale, max_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     detector \u001b[38;5;241m=\u001b[39m detection\u001b[38;5;241m.\u001b[39mDetector()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m recognition\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m scale\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m detector\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:388\u001b[0m, in \u001b[0;36mRecognizer.__init__\u001b[1;34m(self, alphabet, weights, build_params)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet \u001b[38;5;241m=\u001b[39m alphabet\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblank_label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(alphabet)\n\u001b[0;32m    383\u001b[0m (\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_model,\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_model,\n\u001b[1;32m--> 388\u001b[0m ) \u001b[38;5;241m=\u001b[39m build_model(alphabet\u001b[38;5;241m=\u001b[39malphabet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_params)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     weights_dict \u001b[38;5;241m=\u001b[39m PRETRAINED_WEIGHTS[weights]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_ocr\\recognition.py:277\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(alphabet, height, width, color, filters, rnn_units, dropout, rnn_steps_to_discard, pool_size, stn)\u001b[0m\n\u001b[0;32m    275\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten()(locnet_y)\n\u001b[0;32m    276\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(locnet_y)\n\u001b[1;32m--> 277\u001b[0m locnet_y \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m    279\u001b[0m     weights\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    280\u001b[0m         np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m6\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    281\u001b[0m         np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[0;32m    282\u001b[0m     ],\n\u001b[0;32m    283\u001b[0m )(locnet_y)\n\u001b[0;32m    284\u001b[0m localization_net \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mstn_input_layer, outputs\u001b[38;5;241m=\u001b[39mlocnet_y)\n\u001b[0;32m    285\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(_transform, output_shape\u001b[38;5;241m=\u001b[39mstn_input_output_shape)(\n\u001b[0;32m    286\u001b[0m     [x, localization_net(x)]\n\u001b[0;32m    287\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     units,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Tata Steel Internship\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'weights': [array([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]], dtype=float32), array([1., 0., 0., 0., 1., 0.], dtype=float32)]}"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#General Approach.....\n",
    "#Use keras OCR to detect text, define a mask around the text, and inpaint the\n",
    "#masked regions to remove the text.\n",
    "#To apply the mask we need to provide the coordinates of the starting and \n",
    "#the ending points of the line, and the thickness of the line\n",
    "\n",
    "#The start point will be the mid-point between the top-left corner and \n",
    "#the bottom-left corner of the box. \n",
    "#the end point will be the mid-point between the top-right corner and the bottom-right corner.\n",
    "#The following function does exactly that.\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2)/2)\n",
    "    y_mid = int((y1 + y2)/2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "#Main function that detects text and inpaints. \n",
    "#Inputs are the image path and kreas_ocr pipeline\n",
    "def inpaint_text(img_path, pipeline):\n",
    "    # read the image \n",
    "    img = keras_ocr.tools.read(img_path) \n",
    "    \n",
    "    # Recogize text (and corresponding regions)\n",
    "    # Each list of predictions in prediction_groups is a list of\n",
    "    # (word, box) tuples. \n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    \n",
    "    #Define the mask for inpainting\n",
    "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    for box in prediction_groups[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1] \n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3] \n",
    "        \n",
    "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "        \n",
    "        #For the line thickness, we will calculate the length of the line between \n",
    "        #the top-left corner and the bottom-left corner.\n",
    "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
    "        \n",
    "        #Define the line and inpaint\n",
    "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,    \n",
    "        thickness)\n",
    "        inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "                 \n",
    "    return(inpainted_img)\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "img_text_removed = inpaint_text('2.png', pipeline)\n",
    "\n",
    "plt.imshow(img_text_removed)\n",
    "\n",
    "cv2.imwrite('no_nums2.png', cv2.cvtColor(img_text_removed, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9397be7-bbb4-4570-b36a-984f4a3ad849",
   "metadata": {},
   "source": [
    "###### codedebugger\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('2-transformed.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Gaussian Blur\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 25\n",
    "thresh = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "#3.png : 23, 2.png : 155 - 160 , \n",
    "\n",
    "#removing noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area < 200: # Change this threshold value according to your image\n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61432f76-4a68-4fd1-8ea3-7a2ed15339f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa481cb-c5ec-443f-9784-c527ad48a388",
   "metadata": {},
   "source": [
    "## Getting a Hollow Image but smooth Internal Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e88ae4f-588b-4763-b3cb-a1e4205566e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying gaussian blur to improve clarity\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('2.png', 0)\n",
    "\n",
    "# Apply Gaussian blurring to reduce noise\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Applying Bilateral Filtering\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.bilateralFilter(gray, 20, 15, 18)\n",
    "# cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# canny_image = cv2.Canny(gray, 23, 55)\n",
    "# cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Apply adaptive thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 142, 255, cv2.THRESH_BINARY_INV)\n",
    "#3.png : 75, 2.png : 142-150\n",
    "\n",
    "# Apply morphological operations to remove noise and fill in gaps\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 255:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, (0), 1)\n",
    "\n",
    "# Display the processed image\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "675ace2a-0542-419b-932a-842ae3196382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6c4bc29-9a4d-4586-bfb0-86c43aa98d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('3.png', 0)\n",
    "\n",
    "# Apply Gaussian blurring to reduce noise\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Apply adaptive thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 50 , 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Apply morphological operations to remove noise and fill in gaps\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 255:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, 0, 1)\n",
    "\n",
    "# Display the processed image\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bb6f2ff-d9b9-4d2b-a093-b308de95d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Gaussian Blur\n",
    "image = cv2.GaussianBlur(image, (9, 7), 0)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 25 \n",
    "thresh = cv2.threshold(gray, 18, 255, cv2.THRESH_BINARY_INV)[1] \n",
    "#3.png : 23, 2.png : 155 - 160 , \n",
    "\n",
    "#removing noise\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 2)) \n",
    "# thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "#Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours: \n",
    "        area = cv2.contourArea(cnt) \n",
    "        if area < 200: # Change this threshold value according to your image \n",
    "            cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "#Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "#Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0722c18-40fd-42b8-8cf2-8cd54b483ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "#Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "#Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Gaussian Blur\n",
    "image = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "#Threshold the image\n",
    "threshold_value = 25\n",
    "thresh = cv2.threshold(gray, 23, 255, cv2.THRESH_BINARY_INV)[1] \n",
    "#3.png : 23, 2.png : 155 - 160 ,\n",
    "\n",
    "#Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cv2.imshow('Contours', contours)\n",
    "\n",
    "#removing noise \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('NoNoise', thresh)\n",
    "\n",
    "#Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "#Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 200: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "#Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "#Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ab5966a-4362-48d4-ad39-00731f9f1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Canny Edge detection\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "#Read image\n",
    "img = cv2.imread('2-transformed.png')\n",
    "\n",
    "#Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Gaussian Blur\n",
    "image = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 100, 100)\n",
    "\n",
    "#Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Threshold the image\n",
    "threshold_value = 30\n",
    "thresh = cv2.threshold(gray, 23, 255, cv2.THRESH_BINARY_INV)[1] \n",
    "#3.png : 23, 2.png : 155 - 160 ,\n",
    "\n",
    "#removing noise \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 1)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "#Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 500: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "#Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "#Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a4c3d-df72-4928-bd54-d513699a4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below finds the contour area and since we have set a threshold value of contour anything\n",
    "# with an area less than thresh value is potentially a number, parts with larger areas are drawn onto the white image (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf5fe66e-11c7-4d28-8034-3f6c31a209bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 100, 100)\n",
    "cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Gaussian Blur\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 50\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Smooth', thresh)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 60: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf79da67-6786-4f38-90b2-b504dc6ff820",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Find contours of the white regions\u001b[39;00m\n\u001b[0;32m     15\u001b[0m contours, hierarchy \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(canny_image, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[1;32m---> 17\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontours\u001b[39m\u001b[38;5;124m'\u001b[39m, contours)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Gaussian Blur\u001b[39;00m\n\u001b[0;32m     20\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray, (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 100, 100)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.imshow('contours', contours)\n",
    "\n",
    "# Gaussian Blur\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 50\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 60: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6725f-2713-4009-852d-8da62966b25a",
   "metadata": {},
   "source": [
    "## No Numbers but jagged internal Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18b43054-6283-4579-8e25-6e0423ff6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 23, 55)\n",
    "cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Gaussian Blur\n",
    "#gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "# Getting Better results with bilateral filtering\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 20, 15, 18)\n",
    "cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 20\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Smooth', thresh)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 0: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "233df3de-08e8-463f-a483-52aeab009114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('2.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Preprocessing\n",
    "# 1. Convert to grayscale and apply bilateral filtering (improves edge preservation)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 11, 17, 17)  # Adjust parameters as needed\n",
    "\n",
    "# 2. Adaptive thresholding (better handles uneven lighting)\n",
    "thresh_value = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "# Morphological operations for noise removal\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "thresh = cv2.morphologyEx(thresh_value, cv2.MORPH_OPEN, kernel)\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Invert the image (foreground becomes white)\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "cv2.imshow('thresh', thresh)\n",
    "\n",
    "# Find contours of potential number regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Improved number detection logic\n",
    "def is_number_contour(cnt):\n",
    "  # Filter based on area, aspect ratio, and solidity (convexity)\n",
    "  area = cv2.contourArea(cnt)\n",
    "  x, y, w, h = cv2.boundingRect(cnt)\n",
    "  aspect_ratio = float(w)/h\n",
    "  solidity = cv2.contourArea(cnt) / cv2.contourArea(cv2.convexHull(cnt))\n",
    "  return 10 < area < 30 and 0.2 < aspect_ratio < 1.0 and solidity > 0.7\n",
    "\n",
    "# Create a mask image with only black regions (potential numbers)\n",
    "mask = np.zeros_like(thresh)\n",
    "for cnt in contours:\n",
    "  if is_number_contour(cnt):\n",
    "    cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1739c29a-238a-46e7-855c-ed50833ae74c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#Contours\u001b[39;00m\n\u001b[0;32m     17\u001b[0m contours, hierarchy \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(canny_image, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[1;32m---> 18\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContours\u001b[39m\u001b[38;5;124m'\u001b[39m, contours)\n\u001b[0;32m     20\u001b[0m filtered_contours \u001b[38;5;241m=\u001b[39m [cnt \u001b[38;5;28;01mfor\u001b[39;00m cnt \u001b[38;5;129;01min\u001b[39;00m contours \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39marcLength(cnt, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Adaptive Thresholding\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numerical tuple\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read original image\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# Preprocessing to detect the numbers better\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 18)\n",
    "\n",
    "# Canny Edge Detection\n",
    "canny_image = cv2.Canny(gray, 30, 20)\n",
    "\n",
    "#Contours\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Contours', contours)\n",
    "\n",
    "filtered_contours = [cnt for cnt in contours if cv2.arcLength(cnt, True) > 100]\n",
    "\n",
    "# Adaptive Thresholding\n",
    "binary_image_adaptive = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "\n",
    "# Create a mask to remove the numbers\n",
    "mask = np.zeros_like(gray)\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(mask, [cnt], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "#Applying Mask\n",
    "result_without_numbers = cv2.bitwise_and(img, img, mask=~mask)\n",
    "\n",
    "# Convert the result without numbers to grayscale\n",
    "gray_result_without_numbers = cv2.cvtColor(result_without_numbers, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#plotting outputs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(canny_image, cmap='gray')\n",
    "plt.title('Canny Image')\n",
    "\n",
    "#Ploting Canny Image\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(binary_image_adaptive, cmap='gray')\n",
    "plt.title('Adaptive Binary')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e163b173-5e16-44ed-8b20-2dde314a503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read original image\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# Preprocessing for better number detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 18)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "binary_image_adaptive = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 3)\n",
    "\n",
    "# Find contours of the numbers\n",
    "contours, hierarchies = cv2.findContours(binary_image_adaptive, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a mask to remove the numbers\n",
    "mask = np.zeros_like(gray)\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(mask, [cnt], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Apply the mask to remove the numbers\n",
    "result_without_numbers = cv2.bitwise_and(img, img, mask=~mask)\n",
    "\n",
    "# Convert the result without numbers to grayscale\n",
    "gray_result_without_numbers = cv2.cvtColor(result_without_numbers, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find contours of the lines\n",
    "contours_lines, _ = cv2.findContours(gray_result_without_numbers, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours of the lines on a blank image\n",
    "lines_image = np.zeros_like(gray)\n",
    "cv2.drawContours(lines_image, contours_lines, -1, 255, thickness=1)\n",
    "\n",
    "# Plotting outputs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Plot the Adaptive Binary image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(binary_image_adaptive, cmap='gray')\n",
    "plt.title('Adaptive Binary Image')\n",
    "\n",
    "# Plot the image without numbers\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Gray')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d455d611-705c-422b-bbbe-9190db6b4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Read original image\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# Preprocessing for better number detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 20)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "binary_image_adaptive = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Find contours of the numbers\n",
    "contours, _ = cv2.findContours(binary_image_adaptive, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a mask to remove the numbers\n",
    "mask = np.zeros_like(gray)\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(mask, [cnt], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Apply the mask to remove the numbers\n",
    "result_without_numbers = cv2.bitwise_and(img, img, mask=~mask)\n",
    "\n",
    "# Convert the result without numbers to grayscale\n",
    "gray_result_without_numbers = cv2.cvtColor(result_without_numbers, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find contours of the lines\n",
    "contours_lines, _ = cv2.findContours(gray_result_without_numbers, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours of the lines on a blank image\n",
    "lines_image = np.zeros_like(gray)\n",
    "cv2.drawContours(lines_image, contours_lines, -1, (255), thickness=2)\n",
    "\n",
    "# Invert the image (foreground becomes white)\n",
    "lines_image = cv2.bitwise_not(result_without_numbers)\n",
    "cv2.imshow('thresh', lines_image)\n",
    "\n",
    "# Display the outputs\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Adaptive Binary Image\", binary_image_adaptive)\n",
    "cv2.imshow(\"Image without Numbers\", lines_image)\n",
    "\n",
    "# Wait for user input\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9e33e1-3b8d-4ac5-ad0a-fc1af3b5f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 10)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 20, 20)\n",
    "cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Gaussian Blur\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 120\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 2)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Smooth', thresh)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    if perimeter > 100: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979b955b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Reattempting fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6402e4ac-55a0-402a-825f-0076ee800d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53292489-60ac-4f91-9e20-4c7f585fe735",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"3.pdf\")\n",
    "page = doc[0]\n",
    "paths = page.get_drawings()  # extract existing drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f0462f-e908-46e6-9ad2-c555490b1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some output page with the same dimensions\n",
    "outpdf = fitz.open()\n",
    "outpage = outpdf.new_page(width=page.rect.width, height=page.rect.height)\n",
    "shape = outpage.new_shape()  # make a drawing canvas for the output page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36aff411-20ab-4779-b491-f99b75744441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# loop through the paths and draw them\n",
    "# --------------------------------------\n",
    "for path in paths:\n",
    "    # ------------------------------------\n",
    "    # draw each entry of the 'items' list\n",
    "    # ------------------------------------\n",
    "    for item in path[\"items\"]:  # these are the draw commands\n",
    "        if item[0] == \"l\":  # line\n",
    "            shape.draw_line(item[1], item[2])\n",
    "        elif item[0] == \"re\":  # rectangle\n",
    "            shape.draw_rect(item[1])\n",
    "        elif item[0] == \"qu\":  # quad\n",
    "            shape.draw_quad(item[1])\n",
    "        elif item[0] == \"c\":  # curve\n",
    "            shape.draw_bezier(item[1], item[2], item[3], item[4])\n",
    "        else:\n",
    "            raise ValueError(\"unhandled drawing\", item)\n",
    "    # ------------------------------------------------------\n",
    "    # all items are drawn, now apply the common properties\n",
    "    # to finish the path\n",
    "    # ------------------------------------------------------\n",
    "    shape.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53d49855-426c-4d15-aa6f-cad5110831b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all paths processed - commit the shape to its page\n",
    "shape.commit()\n",
    "outpdf.save(\"nums_removed.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e099c583-6a9a-4cc0-9cbf-5766e1e439c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc51f483-b2dd-445e-8aeb-727483c547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open('nums_removed.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1e0bb5-5f50-47ae-b548-33d2c2308c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = doc.load_page(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8232bf1d-f3a0-4399-b7bd-223b07ac4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = page.get_pixmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e91066a-4934-4883-bee9-014b1604d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pix.save('no_nums.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
