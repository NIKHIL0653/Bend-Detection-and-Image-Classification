{
 "cells": [
  {
   "cell_type": "code",
   "id": "2e4768e6-896d-4188-b4c0-c9e23cbbc3a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:52:54.584951Z",
     "start_time": "2024-11-20T19:52:50.278525Z"
    }
   },
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"2.png\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray', gray)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Display the original image and the edge image\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Edge Image\", edges)\n",
    "\n",
    "# Wait for a key press and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "608d03a3-83b5-47ec-a7e9-3bc8b8e3aef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:52:56.233359Z",
     "start_time": "2024-11-20T19:52:56.218807Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def inpaint_text(img_path, remove_list, pipeline):\n",
    "    # read image\n",
    "    img = cv2.imread(img_path)\n",
    "    # Prediction_groups is a list of (word, box) tuples\n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    #print image with annotation and boxes\n",
    "    keras_ocr.tools.drawAnnotations(image=img, predictions=prediction_groups[0])\n",
    "\n",
    "    for box in prediction_groups[0]:\n",
    "        if box[0] in remove_list:\n",
    "            x0, y0 = box[1][0]\n",
    "            x1, y1 = box[1][1]\n",
    "            x2, y2 = box[1][2]\n",
    "            x3, y3 = box[1][3]\n",
    "            x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "            x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "            thickness = int(math.sqrt((x2 - x1)**2 + (y2 - y1)**2))\n",
    "\n",
    "            # create mask\n",
    "            mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "            cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255, thickness)\n",
    "\n",
    "            # inpaint the image\n",
    "            img_inpainted = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "\n",
    "    return img_inpainted"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "741cb44d-bb6c-475a-b79e-9299544eb204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:53:01.162421Z",
     "start_time": "2024-11-20T19:52:59.847063Z"
    }
   },
   "source": [
    "import skimage.feature\n",
    "\n",
    "def find_edges(img_path):\n",
    "    # load and display original image as grayscale\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # apply Canny edge detection\n",
    "    edges = skimage.feature.canny(\n",
    "        image=image,\n",
    "        sigma=2,\n",
    "        low_threshold=0.1,\n",
    "        high_threshold=0.5\n",
    "    )\n",
    "\n",
    "    # display edges\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    # count edges\n",
    "    edge_count = np.sum(edges)\n",
    "    print(f\"Number of edges: {edge_count}\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mskimage\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_edges\u001B[39m(img_path):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# load and display original image as grayscale\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(img_path, cv2\u001B[38;5;241m.\u001B[39mIMREAD_GRAYSCALE)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'skimage'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b889684-aeae-4f8d-aad9-e8f5efa49e46",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import keras_ocr\n",
    "\n",
    "remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# define pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# read image\n",
    "img = cv2.imread('2.png')\n",
    "\n",
    "# remove numbers from the image\n",
    "img_inpainted = inpaint_text('2.png', remove_list, pipeline)\n",
    "\n",
    "# save the image without numbers\n",
    "cv2.imwrite('2_no_numbers.png', img_inpainted)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87ed95-f188-4b9e-a0a4-5a22c719fafe",
   "metadata": {},
   "source": [
    "# find edges\n",
    "find_edges('2_no_numbers.png')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cdb97e-7e6d-4d1a-9070-67e08075f347",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import keras_ocr\n",
    "import numpy as np\n",
    "from keras_ocr.tools import draw_box_on_image\n",
    "\n",
    "# Define the list of numbers to remove\n",
    "remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Define the image path\n",
    "image_path = 'image.png'\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Recognize text in the image\n",
    "prediction_groups = pipeline.recognize([image_path])[0]\n",
    "\n",
    "# Create a blank image with the same size as the input image\n",
    "height, width, _ = cv2.imread(image_path).shape\n",
    "blank_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Loop through the recognized text and apply a mask on the input image\n",
    "for group in prediction_groups:\n",
    "    for box, text in group:\n",
    "        if text in remove_list:\n",
    "            x, y, w, h = box\n",
    "            # Draw a red rectangle on the input image\n",
    "            draw_box_on_image(image_path, box, color=(0, 0, 255))\n",
    "            # Apply a mask on the blank image\n",
    "            blank_image[y:y+h, x:x+w] = 255\n",
    "\n",
    "# Inpaint the masked regions in the blank image\n",
    "inpainted_image = cv2.inpaint(blank_image, np.array(cv2.bitwise_not(blank_image), dtype=np.uint8), 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "# Save the inpainted image\n",
    "cv2.imwrite('inpainted_image.png', inpainted_image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65e0b7b-3eaa-4e8b-a215-da00ada3d4b8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import cv2\n",
    "import keras_ocr\n",
    "import numpy as np\n",
    "from keras_ocr.tools import read, drawAnnotations\n",
    "\n",
    "# Define the list of numbers to remove\n",
    "remove_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Define the image path\n",
    "image_path = '2.png'\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Recognize text in the image\n",
    "prediction_groups = pipeline.recognize([image_path])[0]\n",
    "\n",
    "# Create a blank image with the same size as the input image\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape\n",
    "blank_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Loop through the recognized text and apply a mask on the input image\n",
    "for group in prediction_groups:\n",
    "    for box, text in group:\n",
    "        if text in remove_list:\n",
    "            x, y, w, h = box\n",
    "            # Apply a mask on the blank image\n",
    "            blank_image[y:y+h, x:x+w] = image[y:y+h, x:x+w]\n",
    "\n",
    "# Inpaint the masked regions in the blank image\n",
    "inpainted_image = cv2.inpaint(blank_image, np.zeros(blank_image.shape, dtype=np.uint8), 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "# Save the inpainted image\n",
    "cv2.imwrite('2_no_numbers.png', inpainted_image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dfa268-960c-4003-9787-68577d209d1c",
   "metadata": {},
   "source": [
    "# Another approach"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab07fe9-fada-4053-a184-d7a480a1ea98",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#General Approach.....\n",
    "#Use keras OCR to detect text, define a mask around the text, and inpaint the\n",
    "#masked regions to remove the text.\n",
    "#To apply the mask we need to provide the coordinates of the starting and \n",
    "#the ending points of the line, and the thickness of the line\n",
    "\n",
    "#The start point will be the mid-point between the top-left corner and \n",
    "#the bottom-left corner of the box. \n",
    "#the end point will be the mid-point between the top-right corner and the bottom-right corner.\n",
    "#The following function does exactly that.\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2)/2)\n",
    "    y_mid = int((y1 + y2)/2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "#Main function that detects text and inpaints. \n",
    "#Inputs are the image path and kreas_ocr pipeline\n",
    "def inpaint_text(img_path, pipeline):\n",
    "    # read the image \n",
    "    img = keras_ocr.tools.read(img_path) \n",
    "    \n",
    "    # Recogize text (and corresponding regions)\n",
    "    # Each list of predictions in prediction_groups is a list of\n",
    "    # (word, box) tuples. \n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    \n",
    "    #Define the mask for inpainting\n",
    "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    for box in prediction_groups[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1] \n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3] \n",
    "        \n",
    "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "        \n",
    "        #For the line thickness, we will calculate the length of the line between \n",
    "        #the top-left corner and the bottom-left corner.\n",
    "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
    "        \n",
    "        #Define the line and inpaint\n",
    "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,    \n",
    "        thickness)\n",
    "        inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "                 \n",
    "    return(inpainted_img)\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "img_text_removed = inpaint_text('2.png', pipeline)\n",
    "\n",
    "plt.imshow(img_text_removed)\n",
    "\n",
    "cv2.imwrite('2.png', cv2.cvtColor(img_text_removed, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6a2bcc-f6fd-4321-8cd2-8e90bad019e3",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('2.png', 0)\n",
    "\n",
    "# Thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 500:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, (0), 1)\n",
    "\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1d6607c-29da-474b-a269-0bcab349ad8a",
   "metadata": {},
   "source": [
    "cv2.imwrite('processed_image.png', output)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "438b953f-f783-42a1-9c52-e66c9dd710d7",
   "metadata": {},
   "source": [
    "# Getting an output below"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73e0a11-0602-4e31-8984-45314a1be498",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('3.png', 0)\n",
    "\n",
    "# Thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 20, 30, cv2.THRESH_BINARY_INV)\n",
    "# 4.png:46-49, 3.png :20, 2.png:25\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "# # Perform erosion and dilation to remove noise and fill gaps\n",
    "# kernel = np.ones((100,10), np.uint8)\n",
    "# thresh = cv2.erode(thresh, kernel, iterations=50)\n",
    "# thresh = cv2.dilate(thresh, kernel, iterations=50)\n",
    "\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 30:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, (0), 1)\n",
    "\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3bb9e53-6cbc-4972-9534-b1a9fbc31e62",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Threshold the image to create a binary mask\n",
    "_, binary_mask = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# #adaptive threshold\n",
    "# adaptive_thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 17, 7)\n",
    "\n",
    "# Find contours in the binary mask\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "# Draw the detected contours (lines) on the output image\n",
    "for contour in contours:\n",
    "    cv2.drawContours(output, [contour], -1, (0), 2)\n",
    "\n",
    "# Display the output image\n",
    "cv2.imshow('Extracted Lines', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82b90e52-8e7a-4327-8e1c-0bf160ce4089",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "\n",
    "# Load the Keras-OCR pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Read the image\n",
    "image_path = '2.png'\n",
    "image = keras_ocr.tools.read(image_path)\n",
    "\n",
    "# Perform OCR on the image\n",
    "result = pipeline.recognize([image])\n",
    "\n",
    "# Extract the recognized text\n",
    "recognized_text = result[0][0]\n",
    "\n",
    "# Display the recognized text\n",
    "print(\"Recognized Text:\")\n",
    "print(recognized_text)\n",
    "\n",
    "# Display the image with bounding boxes around detected text\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image)\n",
    "keras_ocr.tools.drawAnnotations(image=image, predictions=result, ax=ax)\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42746438-67f6-4d5c-9494-69fe6e4d6423",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#General Approach.....\n",
    "#Use keras OCR to detect text, define a mask around the text, and inpaint the\n",
    "#masked regions to remove the text.\n",
    "#To apply the mask we need to provide the coordinates of the starting and \n",
    "#the ending points of the line, and the thickness of the line\n",
    "\n",
    "#The start point will be the mid-point between the top-left corner and \n",
    "#the bottom-left corner of the box. \n",
    "#the end point will be the mid-point between the top-right corner and the bottom-right corner.\n",
    "#The following function does exactly that.\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2)/2)\n",
    "    y_mid = int((y1 + y2)/2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "#Main function that detects text and inpaints. \n",
    "#Inputs are the image path and kreas_ocr pipeline\n",
    "def inpaint_text(img_path, pipeline):\n",
    "    # read the image \n",
    "    img = keras_ocr.tools.read(img_path) \n",
    "    \n",
    "    # Recogize text (and corresponding regions)\n",
    "    # Each list of predictions in prediction_groups is a list of\n",
    "    # (word, box) tuples. \n",
    "    prediction_groups = pipeline.recognize([img])\n",
    "    \n",
    "    #Define the mask for inpainting\n",
    "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    for box in prediction_groups[0]:\n",
    "        x0, y0 = box[1][0]\n",
    "        x1, y1 = box[1][1] \n",
    "        x2, y2 = box[1][2]\n",
    "        x3, y3 = box[1][3] \n",
    "        \n",
    "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
    "        \n",
    "        #For the line thickness, we will calculate the length of the line between \n",
    "        #the top-left corner and the bottom-left corner.\n",
    "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
    "        \n",
    "        #Define the line and inpaint\n",
    "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,    \n",
    "        thickness)\n",
    "        inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
    "                 \n",
    "    return(inpainted_img)\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "img_text_removed = inpaint_text('2.png', pipeline)\n",
    "\n",
    "plt.imshow(img_text_removed)\n",
    "\n",
    "cv2.imwrite('no_nums2.png', cv2.cvtColor(img_text_removed, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c9397be7-bbb4-4570-b36a-984f4a3ad849",
   "metadata": {},
   "source": [
    "###### codedebugger\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('2-transformed.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Gaussian Blur\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 25\n",
    "thresh = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "#3.png : 23, 2.png : 155 - 160 , \n",
    "\n",
    "#removing noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area < 200: # Change this threshold value according to your image\n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61432f76-4a68-4fd1-8ea3-7a2ed15339f4",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa481cb-c5ec-443f-9784-c527ad48a388",
   "metadata": {},
   "source": [
    "## Getting a Hollow Image but smooth Internal Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e88ae4f-588b-4763-b3cb-a1e4205566e9",
   "metadata": {},
   "source": [
    "# Applying gaussian blur to improve clarity\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('2.png', 0)\n",
    "\n",
    "# Apply Gaussian blurring to reduce noise\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Applying Bilateral Filtering\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.bilateralFilter(gray, 20, 15, 18)\n",
    "# cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# canny_image = cv2.Canny(gray, 23, 55)\n",
    "# cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Apply adaptive thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 142, 255, cv2.THRESH_BINARY_INV)\n",
    "#3.png : 75, 2.png : 142-150\n",
    "\n",
    "# Apply morphological operations to remove noise and fill in gaps\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 255:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, (0), 1)\n",
    "\n",
    "# Display the processed image\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "675ace2a-0542-419b-932a-842ae3196382",
   "metadata": {},
   "source": [
    "# Output"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6c4bc29-9a4d-4586-bfb0-86c43aa98d72",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('3.png', 0)\n",
    "\n",
    "# Apply Gaussian blurring to reduce noise\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Apply adaptive thresholding to get a binary image\n",
    "_, thresh = cv2.threshold(image, 50 , 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Apply morphological operations to remove noise and fill in gaps\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an all-white image\n",
    "output = np.ones_like(image) * 255\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate the area of the contour to identify numbers and lines separately based on their size\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    if area < 255:  # This threshold value may need adjustment depending on the specific image and text size.\n",
    "        continue\n",
    "    \n",
    "    # Draw detected contours (lines) on the white background\n",
    "    cv2.drawContours(output, [contour], -1, 0, 1)\n",
    "\n",
    "# Display the processed image\n",
    "cv2.imshow('Processed Image', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bb6f2ff-d9b9-4d2b-a093-b308de95d9cd",
   "metadata": {},
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Gaussian Blur\n",
    "image = cv2.GaussianBlur(image, (9, 7), 0)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 25 \n",
    "thresh = cv2.threshold(gray, 18, 255, cv2.THRESH_BINARY_INV)[1] \n",
    "#3.png : 23, 2.png : 155 - 160 , \n",
    "\n",
    "#removing noise\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 2)) \n",
    "# thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "#Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours: \n",
    "        area = cv2.contourArea(cnt) \n",
    "        if area < 200: # Change this threshold value according to your image \n",
    "            cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "#Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "#Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0722c18-40fd-42b8-8cf2-8cd54b483ab7",
   "metadata": {},
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "#Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "#Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Gaussian Blur\n",
    "image = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "#Threshold the image\n",
    "threshold_value = 25\n",
    "thresh = cv2.threshold(gray, 23, 255, cv2.THRESH_BINARY_INV)[1] \n",
    "#3.png : 23, 2.png : 155 - 160 ,\n",
    "\n",
    "#Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cv2.imshow('Contours', contours)\n",
    "\n",
    "#removing noise \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('NoNoise', thresh)\n",
    "\n",
    "#Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "#Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 200: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "#Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "#Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ab5966a-4362-48d4-ad39-00731f9f1c45",
   "metadata": {},
   "source": [
    "#Applying Canny Edge detection\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "#Read image\n",
    "img = cv2.imread('2-transformed.png')\n",
    "\n",
    "#Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Gaussian Blur\n",
    "image = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 100, 100)\n",
    "\n",
    "#Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Threshold the image\n",
    "threshold_value = 30\n",
    "thresh = cv2.threshold(gray, 23, 255, cv2.THRESH_BINARY_INV)[1] \n",
    "#3.png : 23, 2.png : 155 - 160 ,\n",
    "\n",
    "#removing noise \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 1)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "#Create a mask image with only the black regions\n",
    "mask = np.zeros_like(gray)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 500: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "#Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "#Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow('Extracted Lines', thresh) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a4c3d-df72-4928-bd54-d513699a4601",
   "metadata": {},
   "source": [
    "# The code below finds the contour area and since we have set a threshold value of contour anything\n",
    "# with an area less than thresh value is potentially a number, parts with larger areas are drawn onto the white image (output)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf5fe66e-11c7-4d28-8034-3f6c31a209bb",
   "metadata": {},
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 100, 100)\n",
    "cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Gaussian Blur\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 50\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Smooth', thresh)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 60: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf79da67-6786-4f38-90b2-b504dc6ff820",
   "metadata": {},
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 100, 100)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.imshow('contours', contours)\n",
    "\n",
    "# Gaussian Blur\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 50\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 60: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "32c6725f-2713-4009-852d-8da62966b25a",
   "metadata": {},
   "source": [
    "## No Numbers but jagged internal Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18b43054-6283-4579-8e25-6e0423ff6c39",
   "metadata": {},
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 23, 55)\n",
    "cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Gaussian Blur\n",
    "#gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "# Getting Better results with bilateral filtering\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 20, 15, 18)\n",
    "cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 20\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Smooth', thresh)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    area = cv2.contourArea(cnt) \n",
    "    if area < 0: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "233df3de-08e8-463f-a483-52aeab009114",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('2.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Preprocessing\n",
    "# 1. Convert to grayscale and apply bilateral filtering (improves edge preservation)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 11, 17, 17)  # Adjust parameters as needed\n",
    "\n",
    "# 2. Adaptive thresholding (better handles uneven lighting)\n",
    "thresh_value = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "# Morphological operations for noise removal\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "thresh = cv2.morphologyEx(thresh_value, cv2.MORPH_OPEN, kernel)\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Invert the image (foreground becomes white)\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "cv2.imshow('thresh', thresh)\n",
    "\n",
    "# Find contours of potential number regions\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Improved number detection logic\n",
    "def is_number_contour(cnt):\n",
    "  # Filter based on area, aspect ratio, and solidity (convexity)\n",
    "  area = cv2.contourArea(cnt)\n",
    "  x, y, w, h = cv2.boundingRect(cnt)\n",
    "  aspect_ratio = float(w)/h\n",
    "  solidity = cv2.contourArea(cnt) / cv2.contourArea(cv2.convexHull(cnt))\n",
    "  return 10 < area < 30 and 0.2 < aspect_ratio < 1.0 and solidity > 0.7\n",
    "\n",
    "# Create a mask image with only black regions (potential numbers)\n",
    "mask = np.zeros_like(thresh)\n",
    "for cnt in contours:\n",
    "  if is_number_contour(cnt):\n",
    "    cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1739c29a-238a-46e7-855c-ed50833ae74c",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read original image\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# Preprocessing to detect the numbers better\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 18)\n",
    "\n",
    "# Canny Edge Detection\n",
    "canny_image = cv2.Canny(gray, 30, 20)\n",
    "\n",
    "#Contours\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Contours', contours)\n",
    "\n",
    "filtered_contours = [cnt for cnt in contours if cv2.arcLength(cnt, True) > 100]\n",
    "\n",
    "# Adaptive Thresholding\n",
    "binary_image_adaptive = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "\n",
    "# Create a mask to remove the numbers\n",
    "mask = np.zeros_like(gray)\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(mask, [cnt], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "#Applying Mask\n",
    "result_without_numbers = cv2.bitwise_and(img, img, mask=~mask)\n",
    "\n",
    "# Convert the result without numbers to grayscale\n",
    "gray_result_without_numbers = cv2.cvtColor(result_without_numbers, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#plotting outputs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(canny_image, cmap='gray')\n",
    "plt.title('Canny Image')\n",
    "\n",
    "#Ploting Canny Image\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(binary_image_adaptive, cmap='gray')\n",
    "plt.title('Adaptive Binary')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e163b173-5e16-44ed-8b20-2dde314a503a",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read original image\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# Preprocessing for better number detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 18)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "binary_image_adaptive = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 3)\n",
    "\n",
    "# Find contours of the numbers\n",
    "contours, hierarchies = cv2.findContours(binary_image_adaptive, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a mask to remove the numbers\n",
    "mask = np.zeros_like(gray)\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(mask, [cnt], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Apply the mask to remove the numbers\n",
    "result_without_numbers = cv2.bitwise_and(img, img, mask=~mask)\n",
    "\n",
    "# Convert the result without numbers to grayscale\n",
    "gray_result_without_numbers = cv2.cvtColor(result_without_numbers, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find contours of the lines\n",
    "contours_lines, _ = cv2.findContours(gray_result_without_numbers, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours of the lines on a blank image\n",
    "lines_image = np.zeros_like(gray)\n",
    "cv2.drawContours(lines_image, contours_lines, -1, 255, thickness=1)\n",
    "\n",
    "# Plotting outputs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Plot the Adaptive Binary image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(binary_image_adaptive, cmap='gray')\n",
    "plt.title('Adaptive Binary Image')\n",
    "\n",
    "# Plot the image without numbers\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Gray')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d455d611-705c-422b-bbbe-9190db6b4c22",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Read original image\n",
    "img = cv2.imread(\"3.png\")\n",
    "\n",
    "# Preprocessing for better number detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 20)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "binary_image_adaptive = cv2.adaptiveThreshold(\n",
    "    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Find contours of the numbers\n",
    "contours, _ = cv2.findContours(binary_image_adaptive, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a mask to remove the numbers\n",
    "mask = np.zeros_like(gray)\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(mask, [cnt], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "# Apply the mask to remove the numbers\n",
    "result_without_numbers = cv2.bitwise_and(img, img, mask=~mask)\n",
    "\n",
    "# Convert the result without numbers to grayscale\n",
    "gray_result_without_numbers = cv2.cvtColor(result_without_numbers, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find contours of the lines\n",
    "contours_lines, _ = cv2.findContours(gray_result_without_numbers, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours of the lines on a blank image\n",
    "lines_image = np.zeros_like(gray)\n",
    "cv2.drawContours(lines_image, contours_lines, -1, (255), thickness=2)\n",
    "\n",
    "# Invert the image (foreground becomes white)\n",
    "lines_image = cv2.bitwise_not(result_without_numbers)\n",
    "cv2.imshow('thresh', lines_image)\n",
    "\n",
    "# Display the outputs\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Adaptive Binary Image\", binary_image_adaptive)\n",
    "cv2.imshow(\"Image without Numbers\", lines_image)\n",
    "\n",
    "# Wait for user input\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9e33e1-3b8d-4ac5-ad0a-fc1af3b5f427",
   "metadata": {},
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread('3.png')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 17, 15, 10)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 20, 20)\n",
    "cv2.imshow('canny-image', canny_image)\n",
    "\n",
    "# Find contours of the white regions\n",
    "contours, hierarchy = cv2.findContours(canny_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Gaussian Blur\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "cv2.imshow('Post-Blur', gray)\n",
    "\n",
    "# Threshold the image\n",
    "threshold_value = 120\n",
    "_, thresh = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "# Remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 2)) \n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Smooth', thresh)\n",
    "\n",
    "# Invert the image\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Create a mask image with only the black regions\n",
    "mask = np.zeros_like(thresh)\n",
    "\n",
    "for cnt in contours: \n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    if perimeter > 100: # Change this threshold value according to your image \n",
    "        cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "result = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "\n",
    "# Display the extracted lines\n",
    "cv2.imshow('Extracted Lines', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Save the image\n",
    "# cv2.imwrite('new_image2.png', result)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979b955b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Reattempting fitz"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6402e4ac-55a0-402a-825f-0076ee800d84",
   "metadata": {},
   "source": [
    "import fitz\n",
    "from PIL import Image"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53292489-60ac-4f91-9e20-4c7f585fe735",
   "metadata": {},
   "source": [
    "doc = fitz.open(\"3.pdf\")\n",
    "page = doc[0]\n",
    "paths = page.get_drawings()  # extract existing drawings"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f0462f-e908-46e6-9ad2-c555490b1a0a",
   "metadata": {},
   "source": [
    "# define some output page with the same dimensions\n",
    "outpdf = fitz.open()\n",
    "outpage = outpdf.new_page(width=page.rect.width, height=page.rect.height)\n",
    "shape = outpage.new_shape()  # make a drawing canvas for the output page"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36aff411-20ab-4779-b491-f99b75744441",
   "metadata": {},
   "source": [
    "# --------------------------------------\n",
    "# loop through the paths and draw them\n",
    "# --------------------------------------\n",
    "for path in paths:\n",
    "    # ------------------------------------\n",
    "    # draw each entry of the 'items' list\n",
    "    # ------------------------------------\n",
    "    for item in path[\"items\"]:  # these are the draw commands\n",
    "        if item[0] == \"l\":  # line\n",
    "            shape.draw_line(item[1], item[2])\n",
    "        elif item[0] == \"re\":  # rectangle\n",
    "            shape.draw_rect(item[1])\n",
    "        elif item[0] == \"qu\":  # quad\n",
    "            shape.draw_quad(item[1])\n",
    "        elif item[0] == \"c\":  # curve\n",
    "            shape.draw_bezier(item[1], item[2], item[3], item[4])\n",
    "        else:\n",
    "            raise ValueError(\"unhandled drawing\", item)\n",
    "    # ------------------------------------------------------\n",
    "    # all items are drawn, now apply the common properties\n",
    "    # to finish the path\n",
    "    # ------------------------------------------------------\n",
    "    shape.finish()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53d49855-426c-4d15-aa6f-cad5110831b4",
   "metadata": {},
   "source": [
    "# all paths processed - commit the shape to its page\n",
    "shape.commit()\n",
    "outpdf.save(\"nums_removed.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e099c583-6a9a-4cc0-9cbf-5766e1e439c7",
   "metadata": {},
   "source": [
    "import PIL"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc51f483-b2dd-445e-8aeb-727483c547cf",
   "metadata": {},
   "source": [
    "doc = fitz.open('nums_removed.pdf')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1e0bb5-5f50-47ae-b548-33d2c2308c20",
   "metadata": {},
   "source": [
    "page = doc.load_page(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8232bf1d-f3a0-4399-b7bd-223b07ac4842",
   "metadata": {},
   "source": [
    "pix = page.get_pixmap()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e91066a-4934-4883-bee9-014b1604d651",
   "metadata": {},
   "source": [
    "img = pix.save('no_nums.jpg')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
